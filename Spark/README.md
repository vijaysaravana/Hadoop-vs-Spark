# Apache Spark

This folder contains the source code for the Spark word count program and a list of files which we used as inputs to the program.

### Inputs

We used 8 files of varying sizes to run the wordcount program - the files are of sizes as mentioned below : 

| FileName | Size (KB)   |
| :---:   | :---: |
| File1.txt | 1680   |
| File2.txt | 3472   |
| File3.txt | 5178   |
| File4.txt | 6463   |
| File5.txt | 9766   |
| File6.txt | 97657   |
| File7.txt | 976563   |
| File8.txt | 9765625   |

File1 to File4 are samples of the text file at https://norvig.com/big.txt. \
File5 to File8 are autogenerated large text files using the following command by incrementing the file size by order of 10 every file: \
`$ base64 /dev/urandom | head -c 10000000 > File5.txt ` 

### Outputs

The outputs of 2 files (File4 and File5) are placed in the outputs folder. The remaining are too big to store on github. The output files have the word and the number of occurrences present in the following fashion: 


(hello, 2)\
(bye, 3)

The `screenshots` folder has the screenshots of the execution the in Spark GUI when it is running on the local cluster. It contains details of the Spark executor, spark job stages and so on. The `log` folder holds the output of the Spark system from the terminal when the program is executed.

### Steps to run

1. Install Apache Hadoop, HDFS and Yarn and Apache spark.
2. Start the dfs nodes (Namenode, Datanode etc) using `sbin/start-dfs.sh` from inside the hadoop installation folder. 
3. Start YARN (Nodemanager and Resourcemanager) using `sbin/start-yarn.sh` from inside the hadoop installation folder.
4. Check if spark is installed properly by running :\
 `$ spark-shell`
5. Store the text file in the hdfs input folder using: \
 `$ bin/hdfs dfs -put inputs/File1.txt input`
6. Run the Spark python word count program using the command : \
 `$  spark-submit wordcount.py`
7. Get the output to pwd using the command : \
 `$ bin/hdfs dfs -get output output`

### Reference 

Source code reference : https://pythonexamples.org/pyspark-word-count-example/