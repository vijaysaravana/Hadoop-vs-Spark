# Hadoop MapReduce

This folder contains the source code for the Map Reduce word count program and a list of files which we used as inputs to the program.

### Inputs

We used 8 files of varying sizes to run the wordcount program - the files are of sizes as mentioned below : 

| FileName | Size (KB)   |
| :---:   | :---: |
| File1.txt | 1680   |
| File2.txt | 3472   |
| File3.txt | 5178   |
| File4.txt | 6463   |
| File5.txt | 9766   |
| File6.txt | 97657   |
| File7.txt | 976563   |
| File8.txt | 9765625   |

File1 to File4 are samples of the text file at https://norvig.com/big.txt. \
File5 to File8 are autogenerated large text files using the following command by incrementing the file size by order of 10 every file: \
`$ base64 /dev/urandom | head -c 10000000 > File5.txt ` 

### Outputs

The outputs of first 4 files are placed in the outputs folder. The remaining are too big to store on github. The output files have the word and the number of occurrences present in the following fashion: 


hello 2 \
bye 3

The `screenshots` folder has the screenshots of the execution the in Apache Hadoop GUI when it is running on the local cluster. 

### Steps to run

1. Install Apache Hadoop, HDFS and Yarn.
2. Start the dfs nodes (Namenode, Datanode etc) using `sbin/start-dfs.sh` from inside the hadoop installation folder. 
3. Start YARN (Nodemanager and Resourcemanager) using `sbin/start-yarn.sh` from inside the hadoop installation folder.
4. Create a jar file from the JAVA source code for the wordcount program as follows using :\
 `$ bin/hadoop com.sun.tools.javac.Main WordCount.java` \
 `$ jar cf wc.jar WordCount*.class`
5. Store the text file in the hdfs input folder using: \
 `$ bin/hdfs dfs -put inputs/File1.txt input`
6. Run the hadoop mapreduce wordcount program using the command : \
 `$  bin/hadoop jar wc.jar WordCount input output`
7. Get the output to pwd using the command : \
 `$ bin/hdfs dfs -get output output`

### Reference 

Source code reference : https://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html